library(sandwich)
library(lmtest)
library(car)
library(tigris)
library(sf)
knitr::opts_chunk$set(out.width = '100%', out.height = '100%',
echo = FALSE, fig.align = 'center',
kable.force.latex = FALSE, message = FALSE)
plot_theme = theme(
text = element_text(size = 24),
axis.text = element_text(size = 18)
)
ggplot2::theme_set(plot_theme)
knitr::include_graphics("uni.jpg")
# Not including taxincl, insincl and debt_incurred because first two only have zero
# and last one only has false
#year_from_start is perfectly correlated with year so we removed it.
data <- acs %>% select(year, density, metro, puma,
hhincome,
rooms, builtyr2, unitsstr, bedrooms,
age, married, male,
complete_plumbing, has_kitchen, statefip,
cpi_rent
) %>%
na.omit() %>%
filter(year >= 2012) %>%
mutate(year = as.factor(year))
# 2col format
# title: "Project"
# output:
#   pdf_document:
# includes:
#   in_header: "longtable.tex"
#   html_document: default
# date: "2024-10-24"
# classoption:
#   - twocolumn
# header-includes:
#   - \setlength{\columnsep}{32pt}
# knitr::opts_knit$set(kable.force.latex = TRUE)
library(tidyverse)
library(knitr)
# Mohamed
library(tidysynth)
# Alejandro
library(maps)
library(mapproj)
library(stargazer)
library(sandwich)
library(lmtest)
library(car)
library(tigris)
library(sf)
knitr::opts_chunk$set(out.width = '100%', out.height = '100%',
echo = FALSE, fig.align = 'center',
kable.force.latex = FALSE, message = FALSE)
plot_theme = theme(
text = element_text(size = 24),
axis.text = element_text(size = 18)
)
ggplot2::theme_set(plot_theme)
knitr::include_graphics("uni.jpg")
acs = readRDS("acs_sample.rds")
# Not including taxincl, insincl and debt_incurred because first two only have zero
# and last one only has false
#year_from_start is perfectly correlated with year so we removed it.
data <- acs %>% select(year, density, metro, puma,
hhincome,
rooms, builtyr2, unitsstr, bedrooms,
age, married, male,
complete_plumbing, has_kitchen, statefip,
cpi_rent
) %>%
na.omit() %>%
filter(year >= 2012) %>%
mutate(year = as.factor(year))
# Set tigris options for retrieving data
options(tigris_use_cache = TRUE)
# Fetch PUMA shapefiles for the required states
# Use a loop or lapply to fetch PUMAs for all statefips in your dataset
puma_shapefiles <- lapply(unique(data$statefip), function(state) {
pumas(state = state, cb = TRUE, year = 2020) # Download PUMAs for the given state
})
# Combine all state shapefiles into a single sf object
puma_combined <- do.call(rbind, puma_shapefiles)
# Filter PUMAs based on the dataset
highlighted_pumas <- puma_combined %>%
filter(as.integer(STATEFP20) %in% data$statefip & as.integer(PUMACE20) %in% data$puma)
map_plot <- ggplot() +
geom_sf(data = puma_combined, fill = "lightgray", color = "white", size = 0.2) + # Background PUMAs
geom_sf(data = highlighted_pumas, fill = "red", color = "black", size = 0.4) +  # Highlighted PUMAs
coord_sf(
xlim = c(-130, -60), # Longitude limits for continental U.S.
ylim = c(20, 55)     # Latitude limits for continental U.S.
) +
theme_minimal() +
labs(title = "Highlighted PUMAs",
caption = "Source: U.S. Census Bureau") +
theme(
plot.title = element_text(size = 20, face = "bold", hjust = 0.5),
plot.caption = element_text(size = 12),
axis.text = element_blank(),  # Remove axis labels for clarity
axis.ticks = element_blank()
)
map_plot
ggsave("highlighted_pumas_zoomed.png", map_plot, width = 12, height = 8, dpi = 300)
data <- data %>% mutate(statefip = as.factor(statefip)) %>% mutate(puma = as.factor(puma))
# Select only numeric variables
numeric_data <- data %>% select_if(is.numeric)
# Summarize the statistics for numeric columns
summary_table <- data.frame(
Variable = colnames(numeric_data),
Mean = round(sapply(numeric_data, mean, na.rm = TRUE), 2),
Variance = round(sapply(numeric_data, var, na.rm = TRUE), 2),
Min = round(sapply(numeric_data, min, na.rm = TRUE), 2),
Max = round(sapply(numeric_data, max, na.rm = TRUE), 2)
)
rownames(summary_table) <- 1:nrow(summary_table)
# Print the table nicely
kable(summary_table, format = "markdown", caption = "Summary Statistics for Numeric Variables")
# Select only factor (categorical) variables
factor_data <- data %>%
select_if(is.factor)
# Summarize the statistics for factor columns
summary_table2 <- data.frame(
Variable = colnames(factor_data),
`Number of Levels` = sapply(factor_data, function(col) length(unique(col))),
`Most Frequent Level` = sapply(factor_data, function(col) names(sort(table(col), decreasing = TRUE)[1])),
`Frequency of Most Frequent Level` = sapply(factor_data, function(col) max(table(col)))
)
# Print the table nicely
kable(summary_table2, format = "markdown", caption = "Summary Statistics for Factor Variables")
fit.lm_acs <- lm(cpi_rent ~ year + density + metro +
hhincome +
rooms+ builtyr2+ unitsstr+ bedrooms+
age+ married+ male+
statefip, data)
summary(fit.lm_acs)
coeftest(fit.lm_acs, vcov=vcovHC, type="HC0")
vif <- vif(fit.lm_acs)
print(vif)
fit.lm_acs_noyear <- lm(cpi_rent ~ density + metro +
hhincome +
rooms+ builtyr2+ unitsstr+ bedrooms+
age+ married+ male+
statefip, data)
summary(fit.lm_acs_noyear)
fit.lm_acs_nostate <- lm(cpi_rent ~ year + density + metro +
hhincome +
rooms+ builtyr2+ unitsstr+ bedrooms+
age+ married+ male, data)
summary(fit.lm_acs_nostate)
fit.lm_acs_nostatenoyear <- lm(cpi_rent ~ density + metro +
hhincome +
rooms+ builtyr2+ unitsstr+ bedrooms+
age+ married+ male, data)
summary(fit.lm_acs_nostatenoyear)
constr = read_csv("CausalAnalysis/Final/ConstructionPriceIndex/CONSTR.csv")
plotConstrVars = function(vars, after = 2012){
constr2 = constr %>%
filter(year >= after) %>%
pivot_longer(all_of(vars))
breaks = (constr2$date %>% unique)[seq(1, length(constr$date), by = 6)]
ggplot(constr2) +
geom_line(aes(x = date, y = value)) +
facet_wrap(name ~ ., ncol = 1, scales = "free_y") +
scale_x_continuous(breaks = breaks,
guide = guide_axis(angle = 45))
}
# Set tigris options for retrieving data
options(tigris_use_cache = TRUE)
# Fetch PUMA shapefiles for the required states
# Use a loop or lapply to fetch PUMAs for all statefips in your dataset
puma_shapefiles <- lapply(unique(data$statefip), function(state) {
pumas(state = state, cb = TRUE, year = 2020) # Download PUMAs for the given state
})
# Combine all state shapefiles into a single sf object
puma_combined <- do.call(rbind, puma_shapefiles)
# Filter PUMAs based on the dataset
highlighted_pumas <- puma_combined %>%
filter(as.integer(STATEFP20) %in% data$statefip & as.integer(PUMACE20) %in% data$puma)
map_plot <- ggplot() +
geom_sf(data = puma_combined, fill = "lightgray", color = "white", size = 0.2) + # Background PUMAs
geom_sf(data = highlighted_pumas, fill = "red", color = "black", size = 0.4) +  # Highlighted PUMAs
coord_sf(
xlim = c(-130, -60), # Longitude limits for continental U.S.
ylim = c(20, 55)     # Latitude limits for continental U.S.
) +
theme_minimal() +
labs(title = "Highlighted PUMAs",
caption = "Source: U.S. Census Bureau") +
theme(
plot.title = element_text(size = 20, face = "bold", hjust = 0.5),
plot.caption = element_text(size = 12),
axis.text = element_blank(),  # Remove axis labels for clarity
axis.ticks = element_blank()
)
map_plot
plotConstrVars("sold_corrected", 0) +
theme(axis.text.x = element_text(angle = 45, hjust = 0))
plotConstrVars(c("sold_corrected", "cpi_mspus"))
plotConstrVars(c("cpi_mspus", "cpi_sold"))
plotConstrVars("sold_corrected_cash")
plotConstrVars(c("constr_corrected", "sold_corrected"))
fmr_synth = read_csv("CausalAnalysis/Final/Minnesota/FMR_synth.csv")
treat_date = 2020
treated_unit = "Minneapolis-St. Paul-Bloomington, MN-WI HUD Metro FMR Area"
synth = fmr_synth %>%
synthetic_control(outcome = price,
unit = areaname22,
time = year,
i_unit = treated_unit,
i_time = treat_date) %>%
generate_predictor(time_window = 2016,
populat = pop2010,
mdom = median_days_on_market,
nlc = new_listing_count,
plc = pending_listing_count,
pic = price_increased_count,
msf = median_square_feet
) %>%
generate_weights() %>%
generate_control()
plot_trends(synth) + plot_theme
plot_differences(synth) + plot_theme
?stargazer
stargazer(fit1, fit2, fit3, fit4, omit = c("year", "state"), dep.var.labels.include = F)
# 2col format
# ---
# title: "Market Factors Affecting Housing Prices"
# author: "A. Laphond, M. Troeger, Mohamed XX, E. Whitehead"
# date: "`r Sys.Date()`"
# output:
#   bookdown::pdf_document2:
#     includes:
#       in_header: "longtable.tex"
#   html_document: default
#   toc: yes
# fig_caption: yes
# bibliography: refs.bib
# nocite: '@*'
# classoption:
#   - twocolumn
# header-includes:
#   - \setlength{\columnsep}{32pt}
# ---
# knitr::opts_knit$set(kable.force.latex = TRUE)
library(tidyverse)
library(knitr)
# Mohamed
library(tidysynth)
# Alejandro
library(maps)
library(mapproj)
library(stargazer)
library(sandwich)
library(lmtest)
library(car)
library(tigris)
library(sf)
knitr::opts_chunk$set(out.width = '75%', out.height = '75%',
echo = FALSE, fig.align = 'center',
message = FALSE)
plot_theme = theme(
text = element_text(size = 16),
axis.text = element_text(size = 12)
)
ggplot2::theme_set(plot_theme)
doacs = TRUE
knitr::include_graphics("uni.jpg")
acs = readRDS("acs_sample.rds")
# Not including taxincl, insincl and debt_incurred because first two only have zero
# and last one only has false
#year_from_start is perfectly correlated with year so we removed it.
data <- acs %>% select(year, density, metro, puma,
hhincome,
rooms, builtyr2, unitsstr, bedrooms,
age, married, male,
complete_plumbing, has_kitchen, statefip,
cpi_rent
) %>%
na.omit() %>%
filter(year >= 2012) %>%
mutate(year = as.factor(year))
# Set tigris options for retrieving data
options(tigris_use_cache = TRUE)
# Fetch PUMA shapefiles for the required states
# Use a loop or lapply to fetch PUMAs for all statefips in your dataset
puma_shapefiles <- lapply(unique(data$statefip), function(state) {
pumas(state = state, cb = TRUE, year = 2020) # Download PUMAs for the given state
})
# Combine all state shapefiles into a single sf object
puma_combined <- do.call(rbind, puma_shapefiles)
# Filter PUMAs based on the dataset
highlighted_pumas <- puma_combined %>%
filter(as.integer(STATEFP20) %in% data$statefip & as.integer(PUMACE20) %in% data$puma)
map_plot <- ggplot() +
geom_sf(data = puma_combined, fill = "lightgray", color = "white", size = 0.2) + # Background PUMAs
geom_sf(data = highlighted_pumas, fill = "red", color = "black", size = 0.4) +  # Highlighted PUMAs
coord_sf(
xlim = c(-130, -60), # Longitude limits for continental U.S.
ylim = c(20, 55)     # Latitude limits for continental U.S.
) +
theme_minimal() +
labs(title = "Highlighted PUMAs",
caption = "Source: U.S. Census Bureau") +
theme(
plot.title = element_text(size = 20, face = "bold", hjust = 0.5),
plot.caption = element_text(size = 12),
axis.text = element_blank(),  # Remove axis labels for clarity
axis.ticks = element_blank()
)
map_plot
ggsave("highlighted_pumas_zoomed.png", map_plot, width = 12, height = 8, dpi = 300)
data <- data %>% mutate(statefip = as.factor(statefip)) %>% mutate(puma = as.factor(puma))
# Select only numeric variables
numeric_data <- data %>% select_if(is.numeric)
# Summarize the statistics for numeric columns
summary_table <- data.frame(
Variable = colnames(numeric_data),
Mean = round(sapply(numeric_data, mean, na.rm = TRUE), 2),
Variance = round(sapply(numeric_data, var, na.rm = TRUE), 2),
Min = round(sapply(numeric_data, min, na.rm = TRUE), 2),
Max = round(sapply(numeric_data, max, na.rm = TRUE), 2)
)
rownames(summary_table) <- 1:nrow(summary_table)
# Print the table nicely
kable(summary_table, format = "markdown", caption = "Summary Statistics for Numeric Variables")
# Select only factor (categorical) variables
factor_data <- data %>%
select_if(is.factor)
# Summarize the statistics for factor columns
summary_table2 <- data.frame(
Variable = colnames(factor_data),
`Number of Levels` = sapply(factor_data, function(col) length(unique(col))),
`Most Frequent Level` = sapply(factor_data, function(col) names(sort(table(col), decreasing = TRUE)[1])),
`Frequency of Most Frequent Level` = sapply(factor_data, function(col) max(table(col)))
)
# Print the table nicely
kable(summary_table2, format = "markdown", caption = "Summary Statistics for Factor Variables")
fit.lm_acs <- lm(cpi_rent ~ year + density + metro +
hhincome +
rooms+ builtyr2+ unitsstr+ bedrooms+
age+ married+ male+
statefip, data)
fit1 = coeftest(fit.lm_acs, vcov=vcovHC, type="HC0")
vif <- vif(fit.lm_acs)
kable(vif, format = "markdown", caption = "VIF values")
fit.lm_acs_noyear <- lm(cpi_rent ~ density + metro +
hhincome +
rooms+ builtyr2+ unitsstr+ bedrooms+
age+ married+ male+
statefip, data)
fit2 = coeftest(fit.lm_acs_noyear, vcov=vcovHC, type="HC0")
fit.lm_acs_nostate <- lm(cpi_rent ~ year + density + metro +
hhincome +
rooms+ builtyr2+ unitsstr+ bedrooms+
age+ married+ male, data)
fit3 = coeftest(fit.lm_acs_nostate, vcov=vcovHC, type="HC0")
fit.lm_acs_nostatenoyear <- lm(cpi_rent ~ density + metro +
hhincome +
rooms+ builtyr2+ unitsstr+ bedrooms+
age+ married+ male, data)
fit4 = coeftest(fit.lm_acs_nostatenoyear, vcov=vcovHC, type = "HC0")
stargazer(fit1, fit2, fit3, fit4, omit = c("year", "state"), dep.var.labels.include = F)
constr = read_csv("CausalAnalysis/Final/ConstructionPriceIndex/CONSTR.csv")
plotConstrVars = function(vars, after = 2012){
constr2 = constr %>%
filter(year >= after) %>%
pivot_longer(all_of(vars))
breaks = (constr2$date %>% unique)[seq(1, length(constr$date), by = 6)]
ggplot(constr2) +
geom_line(aes(x = date, y = value)) +
facet_wrap(name ~ ., ncol = 1, scales = "free_y") +
scale_x_continuous(breaks = breaks,
guide = guide_axis(angle = 45))
}
plotConstrVars("sold_corrected", 0) +
theme(axis.text.x = element_text(angle = 45, hjust = 0))
plotConstrVars(c("sold_corrected", "cpi_mspus"))
plotConstrVars(c("cpi_mspus", "cpi_sold"))
plotConstrVars("sold_corrected_cash")
plotConstrVars(c("constr_corrected", "sold_corrected"))
fmr_synth = read_csv("CausalAnalysis/Final/Minnesota/FMR_synth.csv")
treat_date = 2020
treated_unit = "Minneapolis-St. Paul-Bloomington, MN-WI HUD Metro FMR Area"
synth = fmr_synth %>%
synthetic_control(outcome = price,
unit = areaname22,
time = year,
i_unit = treated_unit,
i_time = treat_date) %>%
generate_predictor(time_window = 2016,
populat = pop2010,
mdom = median_days_on_market,
nlc = new_listing_count,
plc = pending_listing_count,
pic = price_increased_count,
msf = median_square_feet
) %>%
generate_weights() %>%
generate_control()
plot_trends(synth) + plot_theme
stargazer(fit1, fit2, fit3, fit4, omit = c("year", "state"), dep.var.labels.include = F,
column.labels = c("Main specification", "Time FEs only", "State FEs only", "No FEs"))
fmr_synth = read_csv("CausalAnalysis/Final/Minnesota/FMR_synth.csv")
treat_date = 2020
treated_unit = "Minneapolis-St. Paul-Bloomington, MN-WI HUD Metro FMR Area"
synth = fmr_synth %>%
synthetic_control(outcome = price,
unit = areaname22,
time = year,
i_unit = treated_unit,
i_time = treat_date) %>%
generate_predictor(time_window = 2016,
populat = pop2010,
mdom = median_days_on_market,
nlc = new_listing_count,
plc = pending_listing_count,
pic = price_increased_count,
msf = median_square_feet
) %>%
generate_weights() %>%
generate_control()
plot_trends(synth) + plot_theme
tidysynth::grab_outcome()
tidysynth::grab_outcome(synth)
grab_outcome(synth)
grab_outcome(synth) %>%
rename(Synthetic = "Minneapolis-St. Paul-Bloomington, MN-WI HUD Metro FMR Area")
tidysynth::grab_synthetic_control(synth)
grab_synthetic_control(synth) %>%
rename(Synthetic = synth_y, Observed = real_y, Year = time_unit)
setwd("~/Coursework/DatEcon/Project/Econometrics_Project/CausalAnalysis/DID")
fmr_synth = read_csv("CausalAnalysis/Final/Minnesota/FMR_synth.csv")
treat_date = 2020
treated_unit = "Minneapolis-St. Paul-Bloomington, MN-WI HUD Metro FMR Area"
synth = fmr_synth %>%
synthetic_control(outcome = price,
unit = areaname22,
time = year,
i_unit = treated_unit,
i_time = treat_date) %>%
generate_predictor(time_window = 2016,
populat = pop2010,
mdom = median_days_on_market,
nlc = new_listing_count,
plc = pending_listing_count,
pic = price_increased_count,
msf = median_square_feet
) %>%
generate_weights() %>%
generate_control()
plot_trends(synth) + plot_theme
?stargazer
constr = read_csv("CausalAnalysis/Final/ConstructionPriceIndex/CONSTR.csv")
plotConstrVars = function(vars, after = 2012){
constr2 = constr %>%
filter(year >= after) %>%
pivot_longer(all_of(vars))
breaks = (constr2$date %>% unique)[seq(1, length(constr$date), by = 6)]
ggplot(constr2) +
geom_line(aes(x = date, y = value)) +
facet_wrap(name ~ ., ncol = 1, scales = "free_y") +
scale_x_continuous(breaks = breaks,
guide = guide_axis(angle = 45))
}
plotConstrVars("sold_corrected", 0) +
theme(axis.text.x = element_text(angle = 45, hjust = 0))
plotConstrVars(c("sold_corrected", "cpi_mspus"))
plot_theme = theme_minimal() + theme(
text = element_text(size = 16),
axis.text = element_text(size = 12)
)
ggplot2::theme_set(plot_theme)
plotConstrVars("sold_corrected", 0) +
theme(axis.text.x = element_text(angle = 45, hjust = 0))
plotConstrVars(c("sold_corrected", "cpi_mspus"))
plotConstrVars(c("cpi_mspus", "cpi_sold"))
plotConstrVars(c("constr_corrected", "sold_corrected"))
plotConstrVars("sold_corrected_cash")
plotConstrVars("cpi_sold")
fmr_synth = read_csv("CausalAnalysis/Final/Minnesota/FMR_synth.csv")
treat_date = 2020
treated_unit = "Minneapolis-St. Paul-Bloomington, MN-WI HUD Metro FMR Area"
synth = fmr_synth %>%
synthetic_control(outcome = price,
unit = areaname22,
time = year,
i_unit = treated_unit,
i_time = treat_date) %>%
generate_predictor(time_window = 2016,
populat = pop2010,
mdom = median_days_on_market,
nlc = new_listing_count,
plc = pending_listing_count,
pic = price_increased_count,
msf = median_square_feet
) %>%
generate_weights() %>%
generate_control()
plot_trends(synth) + plot_theme + ggtitle("")
grab_synthetic_control(synth) %>%
rename(Synthetic = synth_y, Observed = real_y, Year = time_unit) %>%
mutate(difference = Observed - Synthetic) %>%
kable(caption = "Results of synthetic control")
grab_synthetic_control(synth) %>%
rename(Synthetic = synth_y, Observed = real_y, Year = time_unit) %>%
mutate(Difference = Observed - Synthetic) %>%
kable(caption = "Results of synthetic control")
?saveRDS
?save
